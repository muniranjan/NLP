{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Make possible for python notebooks to import the util as module. This needs to be copied at every python notebook which wants to \n",
    "load the module'''\n",
    "\n",
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "    \n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "\n",
    "\n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "    \n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "        \n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "                                       \n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "        \n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "        \n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "\n",
    "\n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "    \n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "        \n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "        \n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "    \n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from tm_assignment_util.ipynb\n",
      "['catch', 'machine', 'accident', 'inspect', 'maintain', 'excavator', 'magnet', 'machine', 'maintenance', 'carry', 'make', 'jump', 'grappler', 'turn', 'excavator', 'engine', 'grappler', 'spin', 'pin', 'grappler', 'excavator']\n"
     ]
    }
   ],
   "source": [
    "import tm_assignment_util as util\n",
    "myutilObj = util.util()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's Build the Model\n",
    "# Apply preprocessing to every document in the training set\n",
    "X_Toks_Trn = util.X_Cases_Trn.apply(myutilObj.my_tokens_as_text)\n",
    "X_Toks_Tst = util.X_Cases_Tst.apply(myutilObj.my_tokens_as_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "#Build a pipeline: Combine multiple steps into one\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                      ('clf', RandomForestClassifier(n_estimators=11, criterion='gini'))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...imators=11, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_Toks_Trn, util.Y_Cases_Trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      2894\n",
       "unique       12\n",
       "top       Falls\n",
       "freq       1045\n",
       "Name: Cause, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.Y_Cases_Trn.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(X_Toks_Tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 85  19   0   3   0   0  11   0   0  11   0]\n",
      " [  9  80   0   1   0   1  39   0   0   2   0]\n",
      " [  4   0   9   0   0   0   4   0   0   0   0]\n",
      " [  0   0   0  33   0   0   2   0   0   0   0]\n",
      " [  6   7   2   1   7   0   5   1   0   1   0]\n",
      " [  0   1   0   2   1   3   2  14   0   0   0]\n",
      " [  9  15   1   1   0   0 385   0   0   2   0]\n",
      " [  1   0   0   2   0   2   2  28   0   1   0]\n",
      " [  1   0   0   0   0   0   1   0   7   0   0]\n",
      " [ 17   3   0   0   0   0  10   0   0  23   0]\n",
      " [  6   3   0   0   6   0   4   2   0   1   7]]\n",
      "0.736203090508\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "       Caught in/between Objects       0.62      0.66      0.64       129\n",
      "              Collapse of object       0.62      0.61      0.62       132\n",
      "                        Drowning       0.75      0.53      0.62        17\n",
      "                   Electrocution       0.77      0.94      0.85        35\n",
      " Exposure to Chemical Substances       0.50      0.23      0.32        30\n",
      "Exposure to extreme temperatures       0.50      0.13      0.21        23\n",
      "                           Falls       0.83      0.93      0.88       413\n",
      "             Fires and Explosion       0.62      0.78      0.69        36\n",
      "                           Other       1.00      0.78      0.88         9\n",
      "        Struck By Moving Objects       0.56      0.43      0.49        53\n",
      "                     Suffocation       1.00      0.24      0.39        29\n",
      "\n",
      "                     avg / total       0.73      0.74      0.72       906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test model accuracy\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(util.Y_Cases_Tst, predicted))\n",
    "print(np.mean(predicted == util.Y_Cases_Tst))\n",
    "#y_test.value_counts()\n",
    "print(metrics.classification_report(util.Y_Cases_Tst, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_target_rf = text_clf.predict(util.accidentCases_Osha.Title_Summary_Case.apply(myutilObj.my_tokens_as_text))\n",
    "cleaned_target_rf = util.accidentCases_Osha.Summary.apply(myutilObj.my_tokens_as_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Caught in/between Objects': 4629,\n",
       "         'Caught in/between objects': 6,\n",
       "         'Collapse of object': 1401,\n",
       "         'Drowning': 115,\n",
       "         'Electrocution': 1060,\n",
       "         'Exposure to Chemical Substances': 403,\n",
       "         'Exposure to extreme temperatures': 295,\n",
       "         'Falls': 3052,\n",
       "         'Fires and Explosion': 1206,\n",
       "         'Other': 50,\n",
       "         'Struck By Moving Objects': 558,\n",
       "         'Suffocation': 55})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Counter(predicted_target_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"RF_TAG_file.txt\", \"w\") as output:\n",
    "    for item in predicted_target_rf:\n",
    "        output.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"RF_CLEAN_file.txt\", \"w\") as output:\n",
    "    for item in cleaned_target_rf:\n",
    "        output.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
